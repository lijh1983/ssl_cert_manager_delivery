#!/usr/bin/env python3
"""
SSLè¯ä¹¦ç®¡ç†ç³»ç»Ÿ - ç›®æ ‡æ¸…ç†è„šæœ¬
åŸºäºåŠŸèƒ½å®Œæ•´æ€§åˆ†æç»“æœï¼Œæ‰§è¡Œç²¾ç¡®çš„ä»£ç æ¸…ç†
"""

import os
import sys
import json
import shutil
import logging
import datetime
from pathlib import Path
from typing import Dict, List, Set

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class TargetedCleaner:
    """ç›®æ ‡æ¸…ç†å™¨"""
    
    def __init__(self, project_root: str = '.'):
        """åˆå§‹åŒ–æ¸…ç†å™¨"""
        self.project_root = Path(project_root).resolve()
        
        # æ˜ç¡®è¦åˆ é™¤çš„å†—ä½™æ–‡ä»¶
        self.files_to_delete = [
            # é‡å¤çš„æ•°æ®åº“æ¨¡å‹æ–‡ä»¶
            'backend/src/models/database_postgres.py',  # å·²è¿ç§»åˆ°MySQLï¼ŒPostgreSQLæ–‡ä»¶å†—ä½™
            
            # é‡å¤çš„éƒ¨ç½²æ–‡æ¡£
            'DEPLOYMENT_LOCAL.md',  # ä¸docs/ä¸­çš„éƒ¨ç½²æ–‡æ¡£é‡å¤
            'DEPLOYMENT.md',  # ä¸docs/production_deployment.mdé‡å¤
            
            # é‡å¤çš„è®¾è®¡æ–‡æ¡£
            'DESIGN_DOCUMENT.md',  # ä¸docs/ä¸­çš„è®¾è®¡æ–‡æ¡£é‡å¤
            'DESIGN_DOCUMENT_DETAILED.md',  # è¯¦ç»†è®¾è®¡æ–‡æ¡£é‡å¤
            'DESIGN_DOCUMENT_ENHANCED.md',  # å¢å¼ºè®¾è®¡æ–‡æ¡£é‡å¤
            'DESIGN_DOCUMENT_FINAL.md',  # æœ€ç»ˆè®¾è®¡æ–‡æ¡£é‡å¤
            'DESIGN_DOCUMENT_UPDATED.md',  # æ›´æ–°è®¾è®¡æ–‡æ¡£é‡å¤
            
            # é‡å¤çš„nginxé…ç½®
            'frontend/nginx.conf',  # ä¸nginx/conf.d/ä¸­çš„é…ç½®é‡å¤
            
            # ä¸´æ—¶å’Œå¤‡ä»½æ–‡ä»¶
            'cleanup.log',  # æ¸…ç†è¿‡ç¨‹äº§ç”Ÿçš„ä¸´æ—¶æ—¥å¿—
            'migration.log',  # è¿ç§»è¿‡ç¨‹äº§ç”Ÿçš„ä¸´æ—¶æ—¥å¿—
            
            # æœªä½¿ç”¨çš„æµ‹è¯•æ–‡ä»¶
            'test_*.py',  # å¦‚æœå­˜åœ¨æœªä½¿ç”¨çš„æµ‹è¯•æ–‡ä»¶
            
            # ç©ºçš„æˆ–å ä½ç¬¦æ–‡ä»¶
            'backend/src/utils/__init__.py',  # å¦‚æœåªæ˜¯ç©ºçš„__init__.py
        ]
        
        # è¦åˆ é™¤çš„ç›®å½•æ¨¡å¼
        self.dirs_to_clean = [
            '__pycache__',
            '.pytest_cache',
            'node_modules',
            '.coverage',
            'dist',
            'build'
        ]
        
        # ç»å¯¹ä¸èƒ½åˆ é™¤çš„æ ¸å¿ƒæ–‡ä»¶
        self.protected_files = {
            'backend/src/app.py',
            'backend/src/simple_app.py',
            'backend/src/models/database.py',
            'backend/src/models/certificate.py',
            'backend/src/models/user.py',
            'backend/src/models/server.py',
            'backend/src/models/alert.py',
            'backend/src/services/acme_client.py',
            'backend/src/services/certificate_service.py',
            'backend/src/services/monitoring_service.py',
            'backend/requirements.txt',
            'backend/requirements-prod.txt',
            'docker-compose.production.yml',
            'docker-compose.mysql.yml',
            'nginx/nginx.conf',
            'nginx/conf.d/ssl-manager-production.conf',
            'README.md',
            'docs/production_deployment.md',
            'docs/mysql_deployment.md'
        }
    
    def find_redundant_files(self) -> List[Dict]:
        """æŸ¥æ‰¾å†—ä½™æ–‡ä»¶"""
        redundant_files = []
        
        # 1. æŸ¥æ‰¾é‡å¤çš„è®¾è®¡æ–‡æ¡£
        design_docs = []
        for root, dirs, files in os.walk(self.project_root):
            for file in files:
                if 'DESIGN_DOCUMENT' in file.upper() and file.endswith('.md'):
                    file_path = Path(root) / file
                    relative_path = file_path.relative_to(self.project_root)
                    design_docs.append(str(relative_path))
        
        # ä¿ç•™æœ€é‡è¦çš„è®¾è®¡æ–‡æ¡£ï¼Œåˆ é™¤å…¶ä»–
        if len(design_docs) > 2:
            # ä¿ç•™README.mdå’Œä¸€ä¸ªä¸»è¦çš„è®¾è®¡æ–‡æ¡£
            essential_docs = ['README.md', 'DESIGN_DOCUMENT.md']
            for doc in design_docs:
                if Path(doc).name not in essential_docs:
                    redundant_files.append({
                        'path': doc,
                        'reason': 'Redundant design document',
                        'type': 'documentation'
                    })
        
        # 2. æŸ¥æ‰¾é‡å¤çš„éƒ¨ç½²æ–‡æ¡£
        deployment_docs = []
        for root, dirs, files in os.walk(self.project_root):
            for file in files:
                if 'DEPLOYMENT' in file.upper() and file.endswith('.md'):
                    file_path = Path(root) / file
                    relative_path = file_path.relative_to(self.project_root)
                    deployment_docs.append(str(relative_path))
        
        # ä¿ç•™docs/ç›®å½•ä¸‹çš„éƒ¨ç½²æ–‡æ¡£ï¼Œåˆ é™¤æ ¹ç›®å½•çš„
        for doc in deployment_docs:
            if not doc.startswith('docs/') and doc != 'README.md':
                redundant_files.append({
                    'path': doc,
                    'reason': 'Redundant deployment document (superseded by docs/)',
                    'type': 'documentation'
                })
        
        # 3. æŸ¥æ‰¾è¿‡æ—¶çš„æ•°æ®åº“æ–‡ä»¶
        if (self.project_root / 'backend/src/models/database_postgres.py').exists():
            redundant_files.append({
                'path': 'backend/src/models/database_postgres.py',
                'reason': 'PostgreSQL support removed, migrated to MySQL',
                'type': 'code'
            })
        
        # 4. æŸ¥æ‰¾é‡å¤çš„nginxé…ç½®
        nginx_configs = []
        for root, dirs, files in os.walk(self.project_root):
            for file in files:
                if file.endswith('.conf') and 'nginx' in root.lower():
                    file_path = Path(root) / file
                    relative_path = file_path.relative_to(self.project_root)
                    nginx_configs.append(str(relative_path))
        
        # å¦‚æœæœ‰å¤šä¸ªnginxé…ç½®ï¼Œä¿ç•™ä¸»è¦çš„
        if len(nginx_configs) > 2:
            essential_nginx = ['nginx/nginx.conf', 'nginx/conf.d/ssl-manager-production.conf']
            for config in nginx_configs:
                if config not in essential_nginx:
                    redundant_files.append({
                        'path': config,
                        'reason': 'Redundant nginx configuration',
                        'type': 'configuration'
                    })
        
        return redundant_files
    
    def find_cache_and_temp_files(self) -> List[Dict]:
        """æŸ¥æ‰¾ç¼“å­˜å’Œä¸´æ—¶æ–‡ä»¶"""
        temp_files = []
        
        for root, dirs, files in os.walk(self.project_root):
            # åˆ é™¤ç¼“å­˜ç›®å½•
            dirs_to_remove = []
            for dir_name in dirs:
                if dir_name in self.dirs_to_clean:
                    dir_path = Path(root) / dir_name
                    relative_path = dir_path.relative_to(self.project_root)
                    temp_files.append({
                        'path': str(relative_path),
                        'reason': f'Cache/temporary directory: {dir_name}',
                        'type': 'cache'
                    })
                    dirs_to_remove.append(dir_name)
            
            # ä»dirsåˆ—è¡¨ä¸­ç§»é™¤ï¼Œé¿å…éå†
            for dir_name in dirs_to_remove:
                dirs.remove(dir_name)
            
            # æŸ¥æ‰¾ä¸´æ—¶æ–‡ä»¶
            for file in files:
                file_path = Path(root) / file
                relative_path = file_path.relative_to(self.project_root)
                
                # è·³è¿‡éšè—æ–‡ä»¶
                if file.startswith('.'):
                    continue
                
                # æŸ¥æ‰¾ç‰¹å®šçš„ä¸´æ—¶æ–‡ä»¶
                if (file.endswith('.log') and file in ['cleanup.log', 'migration.log'] or
                    file.endswith('.tmp') or
                    file.endswith('.bak') or
                    file.endswith('.old') or
                    file.endswith('~')):
                    temp_files.append({
                        'path': str(relative_path),
                        'reason': f'Temporary/log file: {file}',
                        'type': 'temporary'
                    })
        
        return temp_files
    
    def find_empty_files(self) -> List[Dict]:
        """æŸ¥æ‰¾ç©ºæ–‡ä»¶"""
        empty_files = []
        
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡éšè—ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            
            for file in files:
                if file.startswith('.'):
                    continue
                
                file_path = Path(root) / file
                relative_path = file_path.relative_to(self.project_root)
                
                # è·³è¿‡å—ä¿æŠ¤çš„æ–‡ä»¶
                if str(relative_path) in self.protected_files:
                    continue
                
                try:
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    if file_path.stat().st_size == 0:
                        # ç‰¹æ®Šå¤„ç†__init__.pyæ–‡ä»¶
                        if file == '__init__.py':
                            # æ£€æŸ¥æ˜¯å¦çœŸçš„éœ€è¦è¿™ä¸ª__init__.py
                            parent_dir = file_path.parent
                            py_files = list(parent_dir.glob('*.py'))
                            if len(py_files) <= 1:  # åªæœ‰__init__.pyæœ¬èº«
                                empty_files.append({
                                    'path': str(relative_path),
                                    'reason': 'Empty __init__.py in directory with no other Python files',
                                    'type': 'empty'
                                })
                        else:
                            empty_files.append({
                                'path': str(relative_path),
                                'reason': 'Empty file',
                                'type': 'empty'
                            })
                except OSError:
                    continue
        
        return empty_files
    
    def create_cleanup_plan(self) -> Dict:
        """åˆ›å»ºæ¸…ç†è®¡åˆ’"""
        logger.info("åˆ›å»ºæ¸…ç†è®¡åˆ’...")
        
        plan = {
            'redundant_files': self.find_redundant_files(),
            'cache_and_temp': self.find_cache_and_temp_files(),
            'empty_files': self.find_empty_files(),
            'protected_files': list(self.protected_files),
            'summary': {}
        }
        
        # åˆå¹¶æ‰€æœ‰è¦åˆ é™¤çš„æ–‡ä»¶
        all_files_to_delete = []
        all_files_to_delete.extend(plan['redundant_files'])
        all_files_to_delete.extend(plan['cache_and_temp'])
        all_files_to_delete.extend(plan['empty_files'])
        
        # å®‰å…¨æ£€æŸ¥ - ç¡®ä¿å—ä¿æŠ¤çš„æ–‡ä»¶ä¸è¢«åˆ é™¤
        safe_files_to_delete = []
        for file_info in all_files_to_delete:
            if file_info['path'] not in self.protected_files:
                safe_files_to_delete.append(file_info)
            else:
                logger.warning(f"Protected file skipped: {file_info['path']}")
        
        plan['files_to_delete'] = safe_files_to_delete
        plan['summary'] = {
            'total_files': len(safe_files_to_delete),
            'redundant_count': len(plan['redundant_files']),
            'cache_temp_count': len(plan['cache_and_temp']),
            'empty_count': len(plan['empty_files']),
            'protected_count': len(self.protected_files)
        }
        
        return plan
    
    def execute_cleanup(self, plan: Dict, dry_run: bool = True) -> bool:
        """æ‰§è¡Œæ¸…ç†"""
        logger.info(f"æ‰§è¡Œæ¸…ç† (dry_run={dry_run})...")
        
        success_count = 0
        error_count = 0
        
        for file_info in plan['files_to_delete']:
            file_path = self.project_root / file_info['path']
            
            try:
                if file_path.exists():
                    if not dry_run:
                        if file_path.is_file():
                            file_path.unlink()
                        elif file_path.is_dir():
                            shutil.rmtree(file_path)
                    
                    logger.info(f"{'[DRY RUN] ' if dry_run else ''}åˆ é™¤: {file_info['path']} - {file_info['reason']}")
                    success_count += 1
                else:
                    logger.debug(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_info['path']}")
            
            except Exception as e:
                logger.error(f"åˆ é™¤å¤±è´¥ {file_info['path']}: {e}")
                error_count += 1
        
        logger.info(f"æ¸…ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {error_count}")
        return error_count == 0
    
    def generate_report(self, plan: Dict, executed: bool = False) -> str:
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        timestamp = datetime.datetime.now().isoformat()
        
        report = {
            'timestamp': timestamp,
            'executed': executed,
            'plan': plan
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        json_report_path = self.project_root / 'targeted_cleanup_report.json'
        with open(json_report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆå¯è¯»æŠ¥å‘Š
        readable_report = f"""
SSLè¯ä¹¦ç®¡ç†ç³»ç»Ÿ - ç›®æ ‡æ¸…ç†æŠ¥å‘Š
===============================

æ¸…ç†æ—¶é—´: {timestamp}
æ‰§è¡ŒçŠ¶æ€: {'å·²æ‰§è¡Œ' if executed else 'è®¡åˆ’ä¸­'}

æ¸…ç†ç»Ÿè®¡:
- æ€»æ–‡ä»¶æ•°: {plan['summary']['total_files']}
- å†—ä½™æ–‡ä»¶: {plan['summary']['redundant_count']}
- ç¼“å­˜/ä¸´æ—¶æ–‡ä»¶: {plan['summary']['cache_temp_count']}
- ç©ºæ–‡ä»¶: {plan['summary']['empty_count']}
- å—ä¿æŠ¤æ–‡ä»¶: {plan['summary']['protected_count']}

æ¸…ç†è¯¦æƒ…:
"""
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        for category, files in [
            ('å†—ä½™æ–‡ä»¶', plan['redundant_files']),
            ('ç¼“å­˜å’Œä¸´æ—¶æ–‡ä»¶', plan['cache_and_temp']),
            ('ç©ºæ–‡ä»¶', plan['empty_files'])
        ]:
            if files:
                readable_report += f"\n{category}:\n"
                for file_info in files:
                    readable_report += f"  - {file_info['path']} ({file_info['reason']})\n"
        
        readable_report += f"\nå—ä¿æŠ¤çš„æ ¸å¿ƒæ–‡ä»¶ (å…±{len(plan['protected_files'])}ä¸ª):\n"
        for protected_file in sorted(plan['protected_files'])[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            readable_report += f"  - {protected_file}\n"
        
        if len(plan['protected_files']) > 10:
            readable_report += f"  ... è¿˜æœ‰ {len(plan['protected_files']) - 10} ä¸ªæ–‡ä»¶\n"
        
        # ä¿å­˜å¯è¯»æŠ¥å‘Š
        txt_report_path = self.project_root / 'targeted_cleanup_report.txt'
        with open(txt_report_path, 'w', encoding='utf-8') as f:
            f.write(readable_report)
        
        return str(txt_report_path)
    
    def run_targeted_cleanup(self, dry_run: bool = True) -> bool:
        """è¿è¡Œç›®æ ‡æ¸…ç†"""
        logger.info("å¼€å§‹ç›®æ ‡æ¸…ç†...")
        
        try:
            # åˆ›å»ºæ¸…ç†è®¡åˆ’
            plan = self.create_cleanup_plan()
            
            # ç”Ÿæˆè®¡åˆ’æŠ¥å‘Š
            report_path = self.generate_report(plan, executed=False)
            logger.info(f"æ¸…ç†è®¡åˆ’å·²ç”Ÿæˆ: {report_path}")
            
            # æ‰§è¡Œæ¸…ç†
            success = self.execute_cleanup(plan, dry_run)
            
            # ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
            if not dry_run:
                final_report_path = self.generate_report(plan, executed=True)
                logger.info(f"æ¸…ç†æ‰§è¡ŒæŠ¥å‘Š: {final_report_path}")
            
            return success
            
        except Exception as e:
            logger.error(f"ç›®æ ‡æ¸…ç†å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='SSLè¯ä¹¦ç®¡ç†ç³»ç»Ÿç›®æ ‡æ¸…ç†å·¥å…·')
    parser.add_argument('--project-root', default='.', help='é¡¹ç›®æ ¹ç›®å½•')
    parser.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œï¼Œä¸å®é™…åˆ é™¤æ–‡ä»¶')
    parser.add_argument('--execute', action='store_true', help='å®é™…æ‰§è¡Œæ¸…ç†ï¼ˆå±é™©æ“ä½œï¼‰')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # å®‰å…¨æ£€æŸ¥
    if args.execute and args.dry_run:
        print("é”™è¯¯: --execute å’Œ --dry-run ä¸èƒ½åŒæ—¶ä½¿ç”¨")
        sys.exit(1)
    
    if args.execute:
        response = input("âš ï¸  æ‚¨ç¡®å®šè¦æ‰§è¡Œå®é™…çš„æ–‡ä»¶åˆ é™¤æ“ä½œå—ï¼Ÿè¿™ä¸ªæ“ä½œä¸å¯é€†ï¼(yes/no): ")
        if response.lower() != 'yes':
            print("æ“ä½œå·²å–æ¶ˆ")
            sys.exit(0)
    
    # è¿è¡Œæ¸…ç†
    cleaner = TargetedCleaner(args.project_root)
    
    dry_run = not args.execute
    if cleaner.run_targeted_cleanup(dry_run=dry_run):
        if dry_run:
            print("\nâœ… æ¸…ç†è®¡åˆ’ç”ŸæˆæˆåŠŸï¼è¯·æŸ¥çœ‹æŠ¥å‘Šæ–‡ä»¶ã€‚")
            print("å¦‚éœ€å®é™…æ‰§è¡Œæ¸…ç†ï¼Œè¯·ä½¿ç”¨ --execute å‚æ•°")
        else:
            print("\nğŸ‰ ç›®æ ‡æ¸…ç†æ‰§è¡ŒæˆåŠŸï¼")
        sys.exit(0)
    else:
        print("\nğŸ’¥ ç›®æ ‡æ¸…ç†å¤±è´¥ï¼")
        sys.exit(1)


if __name__ == '__main__':
    main()
