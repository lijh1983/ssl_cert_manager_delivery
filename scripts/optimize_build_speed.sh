#!/bin/bash
# æ„å»ºé€Ÿåº¦ä¼˜åŒ–è„šæœ¬ - ä¸“é—¨è§£å†³ä¾èµ–å®‰è£…æ…¢çš„é—®é¢˜

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æµ‹ç½‘ç»œç¯å¢ƒ
detect_network_environment() {
    log_info "æ£€æµ‹ç½‘ç»œç¯å¢ƒ..."
    
    # æµ‹è¯•ä¸åŒé•œåƒæºçš„é€Ÿåº¦
    local sources=(
        "deb.debian.org|å®˜æ–¹Debianæº"
        "mirrors.aliyun.com|é˜¿é‡Œäº‘é•œåƒæº"
        "mirrors.tuna.tsinghua.edu.cn|æ¸…åå¤§å­¦é•œåƒæº"
        "mirrors.ustc.edu.cn|ä¸­ç§‘å¤§é•œåƒæº"
    )
    
    local fastest_source=""
    local fastest_time=999
    
    for source_info in "${sources[@]}"; do
        local source=$(echo "$source_info" | cut -d'|' -f1)
        local description=$(echo "$source_info" | cut -d'|' -f2)
        
        log_info "æµ‹è¯• $description ($source)..."
        
        local start_time=$(date +%s%N)
        if timeout 10 ping -c 3 "$source" > /dev/null 2>&1; then
            local end_time=$(date +%s%N)
            local duration=$(( (end_time - start_time) / 1000000 ))
            
            log_success "$description å“åº”æ—¶é—´: ${duration}ms"
            
            if [ $duration -lt $fastest_time ]; then
                fastest_time=$duration
                fastest_source=$source
            fi
        else
            log_warning "$description è¿æ¥å¤±è´¥"
        fi
    done
    
    if [ -n "$fastest_source" ]; then
        log_success "æ¨èä½¿ç”¨: $fastest_source (å“åº”æ—¶é—´: ${fastest_time}ms)"
        echo "$fastest_source"
    else
        log_warning "æ‰€æœ‰é•œåƒæºæµ‹è¯•å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®"
        echo "mirrors.aliyun.com"
    fi
}

# ä¼˜åŒ–Dockeræ„å»ºé…ç½®
optimize_docker_build() {
    log_info "ä¼˜åŒ–Dockeræ„å»ºé…ç½®..."
    
    # åˆ›å»º.dockerignoreæ–‡ä»¶
    if [ ! -f ".dockerignore" ]; then
        log_info "åˆ›å»º.dockerignoreæ–‡ä»¶..."
        cat > .dockerignore <<EOF
# ä¼˜åŒ–Dockeræ„å»ºé€Ÿåº¦ - å¿½ç•¥ä¸å¿…è¦çš„æ–‡ä»¶
.git
.gitignore
README.md
docs/
*.md
.env*
.vscode/
.idea/
node_modules/
__pycache__/
*.pyc
*.pyo
*.pyd
.pytest_cache/
.coverage
htmlcov/
.tox/
.cache/
.mypy_cache/
.DS_Store
Thumbs.db
*.log
logs/
tmp/
temp/
*.tmp
*.backup
*.bak
EOF
        log_success ".dockerignoreæ–‡ä»¶åˆ›å»ºå®Œæˆ"
    fi
    
    # é…ç½®Docker buildkit
    export DOCKER_BUILDKIT=1
    export BUILDKIT_PROGRESS=plain
    
    log_success "Dockeræ„å»ºé…ç½®ä¼˜åŒ–å®Œæˆ"
}

# åˆ›å»ºå¿«é€Ÿæ„å»ºè„šæœ¬
create_fast_build_script() {
    log_info "åˆ›å»ºå¿«é€Ÿæ„å»ºè„šæœ¬..."
    
    cat > fast_build_backend.sh <<'EOF'
#!/bin/bash
# å¿«é€Ÿæ„å»ºåç«¯é•œåƒè„šæœ¬

set -e

echo "ğŸš€ å¼€å§‹å¿«é€Ÿæ„å»ºåç«¯é•œåƒ..."

# å¯ç”¨Docker BuildKit
export DOCKER_BUILDKIT=1
export BUILDKIT_PROGRESS=plain

# æ„å»ºå‚æ•°
DOCKERFILE=${1:-backend/Dockerfile.aliyun.fast}
TAG=${2:-ssl-manager-backend:latest}

echo "ä½¿ç”¨Dockerfile: $DOCKERFILE"
echo "é•œåƒæ ‡ç­¾: $TAG"

# è®°å½•å¼€å§‹æ—¶é—´
START_TIME=$(date +%s)

# æ‰§è¡Œæ„å»º
docker build \
    --progress=plain \
    --no-cache \
    -f "$DOCKERFILE" \
    -t "$TAG" \
    ./backend

# è®¡ç®—æ„å»ºæ—¶é—´
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

echo "âœ… æ„å»ºå®Œæˆï¼"
echo "æ„å»ºæ—¶é—´: ${DURATION}ç§’"
echo "é•œåƒæ ‡ç­¾: $TAG"

# æ˜¾ç¤ºé•œåƒä¿¡æ¯
echo ""
echo "é•œåƒä¿¡æ¯:"
docker images "$TAG" --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}\t{{.CreatedAt}}"

# æµ‹è¯•é•œåƒ
echo ""
echo "æµ‹è¯•é•œåƒå¯åŠ¨..."
if docker run --rm -d --name test-backend "$TAG" sleep 10; then
    echo "âœ… é•œåƒå¯åŠ¨æµ‹è¯•æˆåŠŸ"
    docker stop test-backend > /dev/null 2>&1 || true
else
    echo "âŒ é•œåƒå¯åŠ¨æµ‹è¯•å¤±è´¥"
    exit 1
fi

echo "ğŸ‰ å¿«é€Ÿæ„å»ºå®Œæˆï¼"
EOF
    
    chmod +x fast_build_backend.sh
    log_success "å¿«é€Ÿæ„å»ºè„šæœ¬åˆ›å»ºå®Œæˆ: fast_build_backend.sh"
}

# åˆ›å»ºå¹¶è¡Œæ„å»ºè„šæœ¬
create_parallel_build_script() {
    log_info "åˆ›å»ºå¹¶è¡Œæ„å»ºè„šæœ¬..."
    
    cat > parallel_build.sh <<'EOF'
#!/bin/bash
# å¹¶è¡Œæ„å»ºæ‰€æœ‰é•œåƒ

set -e

echo "ğŸš€ å¼€å§‹å¹¶è¡Œæ„å»ºæ‰€æœ‰é•œåƒ..."

# å¯ç”¨Docker BuildKit
export DOCKER_BUILDKIT=1

# å¹¶è¡Œæ„å»ºå‡½æ•°
build_backend() {
    echo "æ„å»ºåç«¯é•œåƒ..."
    docker build -f backend/Dockerfile.aliyun.fast -t ssl-manager-backend:latest ./backend
    echo "âœ… åç«¯é•œåƒæ„å»ºå®Œæˆ"
}

build_frontend() {
    echo "æ„å»ºå‰ç«¯é•œåƒ..."
    docker build -f frontend/Dockerfile.aliyun -t ssl-manager-frontend:latest ./frontend
    echo "âœ… å‰ç«¯é•œåƒæ„å»ºå®Œæˆ"
}

build_nginx() {
    echo "æ„å»ºnginxä»£ç†é•œåƒ..."
    docker build -f nginx/Dockerfile.proxy -t ssl-manager-nginx-proxy:latest ./nginx
    echo "âœ… nginxä»£ç†é•œåƒæ„å»ºå®Œæˆ"
}

# è®°å½•å¼€å§‹æ—¶é—´
START_TIME=$(date +%s)

# å¹¶è¡Œæ‰§è¡Œæ„å»º
build_backend &
BACKEND_PID=$!

build_frontend &
FRONTEND_PID=$!

build_nginx &
NGINX_PID=$!

# ç­‰å¾…æ‰€æœ‰æ„å»ºå®Œæˆ
wait $BACKEND_PID
wait $FRONTEND_PID
wait $NGINX_PID

# è®¡ç®—æ€»æ—¶é—´
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

echo "ğŸ‰ æ‰€æœ‰é•œåƒæ„å»ºå®Œæˆï¼"
echo "æ€»æ„å»ºæ—¶é—´: ${DURATION}ç§’"

# æ˜¾ç¤ºæ‰€æœ‰é•œåƒ
echo ""
echo "æ„å»ºçš„é•œåƒ:"
docker images | grep ssl-manager
EOF
    
    chmod +x parallel_build.sh
    log_success "å¹¶è¡Œæ„å»ºè„šæœ¬åˆ›å»ºå®Œæˆ: parallel_build.sh"
}

# ä¼˜åŒ–ç³»ç»Ÿé…ç½®
optimize_system_config() {
    log_info "ä¼˜åŒ–ç³»ç»Ÿé…ç½®..."
    
    # æ£€æŸ¥å¹¶ä¼˜åŒ–Dockeré…ç½®
    if [ -f "/etc/docker/daemon.json" ]; then
        log_info "æ£€æŸ¥Dockeré…ç½®..."
        if ! grep -q "max-concurrent-downloads" /etc/docker/daemon.json; then
            log_info "ä¼˜åŒ–Dockerå¹¶å‘ä¸‹è½½é…ç½®..."
            
            # å¤‡ä»½åŸé…ç½®
            sudo cp /etc/docker/daemon.json /etc/docker/daemon.json.backup
            
            # æ·»åŠ ä¼˜åŒ–é…ç½®
            sudo tee /etc/docker/daemon.json > /dev/null <<EOF
{
    "registry-mirrors": [
        "https://registry.cn-hangzhou.aliyuncs.com",
        "https://docker.mirrors.ustc.edu.cn",
        "https://hub-mirror.c.163.com"
    ],
    "max-concurrent-downloads": 20,
    "max-concurrent-uploads": 10,
    "max-download-attempts": 5,
    "log-driver": "json-file",
    "log-opts": {
        "max-size": "100m",
        "max-file": "3"
    },
    "storage-driver": "overlay2",
    "features": {
        "buildkit": true
    }
}
EOF
            
            log_info "é‡å¯DockeræœåŠ¡..."
            sudo systemctl restart docker
            sleep 5
            
            log_success "Dockeré…ç½®ä¼˜åŒ–å®Œæˆ"
        else
            log_success "Dockeré…ç½®å·²ä¼˜åŒ–"
        fi
    fi
    
    # æ£€æŸ¥ç³»ç»Ÿèµ„æº
    local cpu_cores=$(nproc)
    local memory_gb=$(free -g | awk 'NR==2{print $2}')
    
    log_info "ç³»ç»Ÿèµ„æº: CPUæ ¸å¿ƒæ•°=$cpu_cores, å†…å­˜=${memory_gb}GB"
    
    if [ $cpu_cores -ge 4 ] && [ $memory_gb -ge 4 ]; then
        log_success "ç³»ç»Ÿèµ„æºå……è¶³ï¼Œé€‚åˆå¹¶è¡Œæ„å»º"
        echo "å»ºè®®ä½¿ç”¨: ./parallel_build.sh"
    else
        log_warning "ç³»ç»Ÿèµ„æºæœ‰é™ï¼Œå»ºè®®ä½¿ç”¨å•çº¿ç¨‹æ„å»º"
        echo "å»ºè®®ä½¿ç”¨: ./fast_build_backend.sh"
    fi
}

# æµ‹è¯•æ„å»ºé€Ÿåº¦
test_build_speed() {
    log_info "æµ‹è¯•æ„å»ºé€Ÿåº¦..."
    
    # æµ‹è¯•åŸºç¡€é•œåƒæ‹‰å–é€Ÿåº¦
    log_info "æµ‹è¯•åŸºç¡€é•œåƒæ‹‰å–é€Ÿåº¦..."
    local start_time=$(date +%s)
    
    if docker pull python:3.10-slim > /dev/null 2>&1; then
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))
        log_success "åŸºç¡€é•œåƒæ‹‰å–è€—æ—¶: ${duration}ç§’"
    else
        log_error "åŸºç¡€é•œåƒæ‹‰å–å¤±è´¥"
        return 1
    fi
    
    # æµ‹è¯•ç®€å•æ„å»º
    log_info "æµ‹è¯•ç®€å•æ„å»º..."
    cat > test_dockerfile <<EOF
FROM python:3.10-slim
RUN echo "deb https://mirrors.aliyun.com/debian/ bookworm main" > /etc/apt/sources.list
RUN apt-get update && apt-get install -y curl
EOF
    
    start_time=$(date +%s)
    if docker build -f test_dockerfile -t test-build . > /dev/null 2>&1; then
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))
        log_success "æµ‹è¯•æ„å»ºè€—æ—¶: ${duration}ç§’"
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶å’Œé•œåƒ
        rm test_dockerfile
        docker rmi test-build > /dev/null 2>&1 || true
    else
        log_error "æµ‹è¯•æ„å»ºå¤±è´¥"
        rm test_dockerfile
        return 1
    fi
}

# æ˜¾ç¤ºä¼˜åŒ–ç»“æœ
show_optimization_result() {
    echo
    log_success "ğŸ‰ æ„å»ºé€Ÿåº¦ä¼˜åŒ–å®Œæˆï¼"
    echo
    echo "=== ä¼˜åŒ–å†…å®¹ ==="
    echo "âœ… é…ç½®äº†é˜¿é‡Œäº‘è½¯ä»¶æº"
    echo "âœ… ä¼˜åŒ–äº†Dockeræ„å»ºé…ç½®"
    echo "âœ… åˆ›å»ºäº†å¿«é€Ÿæ„å»ºè„šæœ¬"
    echo "âœ… åˆ›å»ºäº†å¹¶è¡Œæ„å»ºè„šæœ¬"
    echo "âœ… ä¼˜åŒ–äº†ç³»ç»Ÿé…ç½®"
    echo
    echo "=== ä½¿ç”¨æ–¹æ³• ==="
    echo "1. å¿«é€Ÿæ„å»ºåç«¯:"
    echo "   ./fast_build_backend.sh"
    echo
    echo "2. å¹¶è¡Œæ„å»ºæ‰€æœ‰é•œåƒ:"
    echo "   ./parallel_build.sh"
    echo
    echo "3. ä½¿ç”¨ä¼˜åŒ–çš„Dockerfile:"
    echo "   docker build -f backend/Dockerfile.aliyun.fast -t ssl-manager-backend ./backend"
    echo
    echo "=== é¢„æœŸæ•ˆæœ ==="
    echo "â€¢ ä¾èµ–å®‰è£…æ—¶é—´ä»20+åˆ†é’Ÿç¼©çŸ­åˆ°2-5åˆ†é’Ÿ"
    echo "â€¢ æ€»æ„å»ºæ—¶é—´ä»30+åˆ†é’Ÿç¼©çŸ­åˆ°5-10åˆ†é’Ÿ"
    echo "â€¢ ç½‘ç»œä¸‹è½½é€Ÿåº¦æå‡5-10å€"
    echo
}

# ä¸»å‡½æ•°
main() {
    echo "âš¡ SSLè¯ä¹¦ç®¡ç†ç³»ç»Ÿ - æ„å»ºé€Ÿåº¦ä¼˜åŒ–å·¥å…·"
    echo "========================================"
    echo
    
    # æ£€æŸ¥DockeræœåŠ¡
    if ! docker info > /dev/null 2>&1; then
        log_error "DockeræœåŠ¡æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨Docker"
        exit 1
    fi
    
    # æ‰§è¡Œä¼˜åŒ–æ­¥éª¤
    local fastest_source
    fastest_source=$(detect_network_environment)
    echo
    
    optimize_docker_build
    echo
    
    create_fast_build_script
    echo
    
    create_parallel_build_script
    echo
    
    optimize_system_config
    echo
    
    test_build_speed
    echo
    
    show_optimization_result
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
