#!/usr/bin/env python3
"""
æ€§èƒ½ä¼˜åŒ–æµ‹è¯•è„šæœ¬
æµ‹è¯•å‰ç«¯å’Œåç«¯çš„æ€§èƒ½ä¼˜åŒ–æ•ˆæœ
"""

import time
import asyncio
import sys
import os
from typing import List, Dict, Any
import json

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# ç¦ç”¨ç›‘æ§çº¿ç¨‹ä»¥é¿å…æµ‹è¯•æ—¶çš„å¹²æ‰°
os.environ['DISABLE_MONITORING'] = '1'

try:
    from src.utils.query_optimizer import (
        query_cache, query_optimizer, optimize_query,
        get_query_performance_report, PaginationHelper
    )
    print("âœ… æŸ¥è¯¢ä¼˜åŒ–æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æŸ¥è¯¢ä¼˜åŒ–æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    # åˆ›å»ºç®€åŒ–ç‰ˆæœ¬ç”¨äºæµ‹è¯•
    class CacheManager:
        def __init__(self, config=None):
            self.cache = {}
        def get(self, key):
            return self.cache.get(key)
        def set(self, key, value):
            self.cache[key] = value
        def clear(self):
            self.cache.clear()
        def getStats(self):
            return {'total_items': len(self.cache)}
    print("âœ… ä½¿ç”¨ç®€åŒ–ç‰ˆç¼“å­˜ç®¡ç†å™¨")


class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.results = {}
        self.cache_manager = CacheManager()
    
    def test_cache_performance(self):
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        print("\n" + "="*50)
        print("ğŸš€ ç¼“å­˜æ€§èƒ½æµ‹è¯•")
        print("="*50)
        
        # æµ‹è¯•æ•°æ®
        test_data = [f"test_data_{i}" for i in range(1000)]
        
        # æµ‹è¯•æ— ç¼“å­˜æ€§èƒ½
        start_time = time.time()
        for i, data in enumerate(test_data):
            # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
            processed = data.upper() + str(i)
        no_cache_time = time.time() - start_time
        
        # æµ‹è¯•æœ‰ç¼“å­˜æ€§èƒ½
        start_time = time.time()
        for i, data in enumerate(test_data):
            cache_key = f"processed_{i}"
            cached_result = self.cache_manager.get(cache_key)
            if cached_result is None:
                processed = data.upper() + str(i)
                self.cache_manager.set(cache_key, processed)
            else:
                processed = cached_result
        with_cache_time = time.time() - start_time
        
        # æµ‹è¯•ç¼“å­˜å‘½ä¸­æ€§èƒ½
        start_time = time.time()
        for i in range(len(test_data)):
            cache_key = f"processed_{i}"
            cached_result = self.cache_manager.get(cache_key)
        cache_hit_time = time.time() - start_time
        
        print(f"ğŸ“Š ç¼“å­˜æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"  æ— ç¼“å­˜å¤„ç†æ—¶é—´: {no_cache_time:.4f}s")
        print(f"  æœ‰ç¼“å­˜å¤„ç†æ—¶é—´: {with_cache_time:.4f}s")
        print(f"  ç¼“å­˜å‘½ä¸­æ—¶é—´: {cache_hit_time:.4f}s")
        print(f"  æ€§èƒ½æå‡: {((no_cache_time - cache_hit_time) / no_cache_time * 100):.1f}%")
        
        # æµ‹è¯•ç¼“å­˜ç»Ÿè®¡
        stats = self.cache_manager.getStats()
        print(f"  ç¼“å­˜ç»Ÿè®¡: {stats}")
        
        self.results['cache'] = {
            'no_cache_time': no_cache_time,
            'with_cache_time': with_cache_time,
            'cache_hit_time': cache_hit_time,
            'improvement': (no_cache_time - cache_hit_time) / no_cache_time * 100,
            'stats': stats
        }
    
    def test_query_optimization(self):
        """æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–"""
        print("\n" + "="*50)
        print("ğŸ” æŸ¥è¯¢ä¼˜åŒ–æµ‹è¯•")
        print("="*50)
        
        # æ¨¡æ‹ŸæŸ¥è¯¢å‡½æ•°
        @optimize_query(cache_ttl=60, monitor=True)
        def mock_database_query(table: str, conditions: Dict[str, Any]):
            """æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢"""
            # æ¨¡æ‹ŸæŸ¥è¯¢å»¶è¿Ÿ
            time.sleep(0.01)  # 10mså»¶è¿Ÿ
            return {
                'table': table,
                'conditions': conditions,
                'results': [f"record_{i}" for i in range(100)],
                'count': 100
            }
        
        # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
        queries = [
            ('users', {'status': 'active'}),
            ('certificates', {'expires_at': '<2024-01-01'}),
            ('servers', {'status': 'online'}),
            ('users', {'status': 'active'}),  # é‡å¤æŸ¥è¯¢ï¼Œæµ‹è¯•ç¼“å­˜
            ('certificates', {'expires_at': '<2024-01-01'}),  # é‡å¤æŸ¥è¯¢
        ]
        
        start_time = time.time()
        for table, conditions in queries:
            result = mock_database_query(table, conditions)
        total_time = time.time() - start_time
        
        print(f"ğŸ“Š æŸ¥è¯¢ä¼˜åŒ–æµ‹è¯•ç»“æœ:")
        print(f"  æ€»æŸ¥è¯¢æ—¶é—´: {total_time:.4f}s")
        print(f"  å¹³å‡æŸ¥è¯¢æ—¶é—´: {total_time/len(queries):.4f}s")
        
        # è·å–æ…¢æŸ¥è¯¢ç»Ÿè®¡
        slow_queries = query_optimizer.get_slow_queries()
        print(f"  æ…¢æŸ¥è¯¢æ•°é‡: {len(slow_queries)}")
        
        # è·å–æŸ¥è¯¢åˆ†æ
        analysis = query_optimizer.analyze_query_patterns()
        print(f"  æŸ¥è¯¢åˆ†æ: {analysis}")
        
        self.results['query_optimization'] = {
            'total_time': total_time,
            'average_time': total_time / len(queries),
            'slow_queries_count': len(slow_queries),
            'analysis': analysis
        }
    
    def test_pagination_performance(self):
        """æµ‹è¯•åˆ†é¡µæ€§èƒ½"""
        print("\n" + "="*50)
        print("ğŸ“„ åˆ†é¡µæ€§èƒ½æµ‹è¯•")
        print("="*50)
        
        # æ¨¡æ‹Ÿå¤§æ•°æ®é›†
        large_dataset = list(range(10000))
        
        def mock_query_with_pagination(offset: int, limit: int):
            """æ¨¡æ‹Ÿåˆ†é¡µæŸ¥è¯¢"""
            time.sleep(0.005)  # 5mså»¶è¿Ÿ
            return large_dataset[offset:offset + limit]
        
        def mock_count_query():
            """æ¨¡æ‹Ÿè®¡æ•°æŸ¥è¯¢"""
            time.sleep(0.002)  # 2mså»¶è¿Ÿ
            return len(large_dataset)
        
        # æµ‹è¯•åˆ†é¡µæ€§èƒ½
        pagination_helper = PaginationHelper()
        
        start_time = time.time()
        result = pagination_helper.paginate(
            query_func=mock_query_with_pagination,
            page=1,
            per_page=20,
            count_func=mock_count_query
        )
        pagination_time = time.time() - start_time
        
        print(f"ğŸ“Š åˆ†é¡µæ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"  åˆ†é¡µæŸ¥è¯¢æ—¶é—´: {pagination_time:.4f}s")
        print(f"  è¿”å›è®°å½•æ•°: {len(result['items'])}")
        print(f"  æ€»è®°å½•æ•°: {result['pagination']['total']}")
        print(f"  æ€»é¡µæ•°: {result['pagination']['total_pages']}")
        print(f"  æŸ¥è¯¢æ—¶é—´: {result['meta']['query_time']:.4f}s")
        print(f"  è®¡æ•°æ—¶é—´: {result['meta']['count_time']:.4f}s")
        
        self.results['pagination'] = {
            'pagination_time': pagination_time,
            'items_count': len(result['items']),
            'total_records': result['pagination']['total'],
            'total_pages': result['pagination']['total_pages'],
            'query_time': result['meta']['query_time'],
            'count_time': result['meta']['count_time']
        }
    
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        print("\n" + "="*50)
        print("ğŸ’¾ å†…å­˜ä½¿ç”¨æµ‹è¯•")
        print("="*50)
        
        import psutil
        import gc
        
        # è·å–å½“å‰è¿›ç¨‹
        process = psutil.Process()
        
        # æµ‹è¯•å‰å†…å­˜ä½¿ç”¨
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
        memory_before = process.memory_info().rss / 1024 / 1024  # MB
        
        # åˆ›å»ºå¤§é‡ç¼“å­˜æ•°æ®
        large_cache = CacheManager({'maxSize': 1000})
        for i in range(1000):
            large_cache.set(f"key_{i}", f"value_{i}" * 100)  # è¾ƒå¤§çš„å€¼
        
        memory_after = process.memory_info().rss / 1024 / 1024  # MB
        
        # æ¸…ç†ç¼“å­˜
        large_cache.clear()
        gc.collect()
        memory_after_cleanup = process.memory_info().rss / 1024 / 1024  # MB
        
        print(f"ğŸ“Š å†…å­˜ä½¿ç”¨æµ‹è¯•ç»“æœ:")
        print(f"  æµ‹è¯•å‰å†…å­˜: {memory_before:.2f} MB")
        print(f"  æµ‹è¯•åå†…å­˜: {memory_after:.2f} MB")
        print(f"  æ¸…ç†åå†…å­˜: {memory_after_cleanup:.2f} MB")
        print(f"  å†…å­˜å¢é•¿: {memory_after - memory_before:.2f} MB")
        print(f"  æ¸…ç†æ•ˆæœ: {memory_after - memory_after_cleanup:.2f} MB")
        
        self.results['memory'] = {
            'memory_before': memory_before,
            'memory_after': memory_after,
            'memory_after_cleanup': memory_after_cleanup,
            'memory_growth': memory_after - memory_before,
            'cleanup_effect': memory_after - memory_after_cleanup
        }
    
    async def test_async_performance(self):
        """æµ‹è¯•å¼‚æ­¥æ€§èƒ½"""
        print("\n" + "="*50)
        print("âš¡ å¼‚æ­¥æ€§èƒ½æµ‹è¯•")
        print("="*50)
        
        async def mock_async_operation(delay: float):
            """æ¨¡æ‹Ÿå¼‚æ­¥æ“ä½œ"""
            await asyncio.sleep(delay)
            return f"result_after_{delay}s"
        
        # æµ‹è¯•ä¸²è¡Œæ‰§è¡Œ
        start_time = time.time()
        for i in range(5):
            await mock_async_operation(0.1)
        serial_time = time.time() - start_time
        
        # æµ‹è¯•å¹¶è¡Œæ‰§è¡Œ
        start_time = time.time()
        tasks = [mock_async_operation(0.1) for _ in range(5)]
        await asyncio.gather(*tasks)
        parallel_time = time.time() - start_time
        
        print(f"ğŸ“Š å¼‚æ­¥æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"  ä¸²è¡Œæ‰§è¡Œæ—¶é—´: {serial_time:.4f}s")
        print(f"  å¹¶è¡Œæ‰§è¡Œæ—¶é—´: {parallel_time:.4f}s")
        print(f"  æ€§èƒ½æå‡: {((serial_time - parallel_time) / serial_time * 100):.1f}%")
        
        self.results['async'] = {
            'serial_time': serial_time,
            'parallel_time': parallel_time,
            'improvement': (serial_time - parallel_time) / serial_time * 100
        }
    
    def generate_report(self):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ æ€§èƒ½ä¼˜åŒ–æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        print("\nğŸ¯ æµ‹è¯•æ€»ç»“:")
        
        if 'cache' in self.results:
            cache_improvement = self.results['cache']['improvement']
            print(f"  â€¢ ç¼“å­˜ä¼˜åŒ–: æ€§èƒ½æå‡ {cache_improvement:.1f}%")
        
        if 'query_optimization' in self.results:
            avg_time = self.results['query_optimization']['average_time']
            print(f"  â€¢ æŸ¥è¯¢ä¼˜åŒ–: å¹³å‡æŸ¥è¯¢æ—¶é—´ {avg_time:.4f}s")
        
        if 'pagination' in self.results:
            pagination_time = self.results['pagination']['pagination_time']
            print(f"  â€¢ åˆ†é¡µä¼˜åŒ–: åˆ†é¡µæŸ¥è¯¢æ—¶é—´ {pagination_time:.4f}s")
        
        if 'memory' in self.results:
            memory_growth = self.results['memory']['memory_growth']
            print(f"  â€¢ å†…å­˜ä¼˜åŒ–: å†…å­˜å¢é•¿ {memory_growth:.2f} MB")
        
        if 'async' in self.results:
            async_improvement = self.results['async']['improvement']
            print(f"  â€¢ å¼‚æ­¥ä¼˜åŒ–: æ€§èƒ½æå‡ {async_improvement:.1f}%")
        
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        
        # æ ¹æ®æµ‹è¯•ç»“æœç”Ÿæˆå»ºè®®
        if 'cache' in self.results and self.results['cache']['improvement'] < 50:
            print("  â€¢ è€ƒè™‘å¢åŠ ç¼“å­˜TTLæˆ–ä¼˜åŒ–ç¼“å­˜ç­–ç•¥")
        
        if 'query_optimization' in self.results:
            slow_queries = self.results['query_optimization']['slow_queries_count']
            if slow_queries > 0:
                print(f"  â€¢ å‘ç° {slow_queries} ä¸ªæ…¢æŸ¥è¯¢ï¼Œå»ºè®®ä¼˜åŒ–")
        
        if 'memory' in self.results and self.results['memory']['memory_growth'] > 100:
            print("  â€¢ å†…å­˜ä½¿ç”¨é‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼")
        
        print("\nğŸ“Š è¯¦ç»†æ•°æ®:")
        print(json.dumps(self.results, indent=2, ensure_ascii=False))
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        with open('performance_report.json', 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° performance_report.json")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ‰ å¼€å§‹SSLè¯ä¹¦ç®¡ç†ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–æµ‹è¯•")
    
    tester = PerformanceTester()
    
    try:
        # æ‰§è¡Œå„é¡¹æ€§èƒ½æµ‹è¯•
        tester.test_cache_performance()
        tester.test_query_optimization()
        tester.test_pagination_performance()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰psutilæ¨¡å—
        try:
            import psutil
            tester.test_memory_usage()
        except ImportError:
            print("\nâš ï¸  psutilæ¨¡å—æœªå®‰è£…ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
        
        await tester.test_async_performance()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        tester.generate_report()
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    asyncio.run(main())
